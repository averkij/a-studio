{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f01255b-c703-4335-be1b-915c32d08f0b",
   "metadata": {},
   "source": [
    "## Prepare datasets\n",
    "\n",
    "In this example we make a parallel datasets in HuggingFace format and upload them to the HF.\n",
    "\n",
    "tg: @lingtrain_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a0ded97-98ec-4d7b-bdd3-86431483dfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datasets import Dataset, DatasetDict\n",
    "import csv\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "#get your token on https://hf.co/settings/token. To upload dataset into lingtrain HF space ask for token token in chat @lingtrain_books.\n",
    "HF_TOKEN = '---------'\n",
    "\n",
    "\n",
    "def make_pairs(lang1, lang2, path1, path2):\n",
    "    data_1 = open(path1).read().splitlines()\n",
    "    data_2 = open(path2).read().splitlines()\n",
    "    print(f'Lengths: len(data_1)={len(data_1)}, len(data_2):{len(data_2)}')\n",
    "\n",
    "    train_items = defaultdict(list)\n",
    "    for item_1, item_2 in zip(data_1, data_2):\n",
    "        train_items[lang1].append(clean(item_1))\n",
    "        train_items[lang2].append(clean(item_2))\n",
    "    return train_items\n",
    "\n",
    "def clean(text):\n",
    "    text = text.replace(u'\\xa0', ' ')\n",
    "    return text\n",
    "\n",
    "def make_dataset(items):\n",
    "    ds = DatasetDict({\n",
    "        'train': Dataset.from_dict(items)\n",
    "    })\n",
    "    return ds\n",
    "\n",
    "def upload_dataset(ds, name):\n",
    "    ds.push_to_hub(f\"{name}\", token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f0485e-70de-42b1-af8a-c2a7a6a2c9e7",
   "metadata": {},
   "source": [
    "### Ingush"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53addc04-1e59-4840-a2b7-6c07f05b5e35",
   "metadata": {},
   "source": [
    "For example let's use Ingush corpora provided by Ruslan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "053d1ef5-4d67-48dd-aa68-09371cb45352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths: len(data_1)=5492, len(data_2):5492\n"
     ]
    }
   ],
   "source": [
    "lang1 = 'ing'\n",
    "lang2 = 'ru'\n",
    "path1 = './ing/parall_ing.txt'\n",
    "path2 = './ing/parall_ru.txt'\n",
    "\n",
    "pairs = make_pairs(lang1, lang2, path1, path2)\n",
    "dataset = make_dataset(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f30e75eb-ac22-4ad7-a981-395d656e8202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ing': 'Ер — Сигаули яхача поселке, цхьан цӀагӀарча ванна чу Рикки-Тикки-Таве ше цхьаь лелабаьча турпалча тӀемах дола дувцар да.',\n",
       " 'ru': 'Это — рассказ о великой войне, которую вёл в одиночку Рикки-Тикки-Тави в ванной большого дома в посёлке Сига́ули.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f2e3c5c-c433-4a67-91f6-ac9f72f4e49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split train to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b6f2466d274779bdff4ee57aff34f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e09ee919de4922b5b621ba958d9779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "upload_dataset(dataset, name='lingtrain/ingush-russian')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
